<configuration>
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
        <!-- 数据块副本数为3 -->
        <property>
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
        <property>
                <name>dfs.permissions.enabled</name>
                <value>false</value>
        </property>
        <!-- 权限默认配置为false -->
        <property>
                <name>dfs.nameservices</name>
                <value>cluster1</value>
        </property>
        <!-- 命名空间，它的值与fs.defaultFS的值要对应，namenode高可用之后有两个namenode，cluster1是对外提供的统一入口 -->
        <property>
                <name>dfs.ha.namenodes.cluster1</name>
                <value>node2,node3</value>
        </property>
        <!-- 指定 nameService 是 cluster1 时的nameNode有哪些，这里的值也是逻辑名称，名字随便起，相互不重复即可 -->
        <property>
                <name>dfs.namenode.rpc-address.cluster1.node2</name>
                <value>node2:9000</value>
        </property>
        <!-- node2 rpc地址 -->
        <property>
                <name>dfs.namenode.http-address.cluster1.node2</name>
                <value>node2:50070</value>
        </property>
        <!-- node2 http地址 -->
        <property>
                <name>dfs.namenode.rpc-address.cluster1.node3</name>
                <value>node3:9000</value>
        </property>
        <!-- node3 rpc地址 -->
        <property>
                <name>dfs.namenode.http-address.cluster1.node3</name>
                <value>node3:50070</value>
        </property>
        <!-- node3 http地址 -->
        <property>
                <name>dfs.ha.automatic-failover.enabled</name>
                <value>true</value>
        </property>
        <!-- 启动故障自动恢复 -->
        <property>
                <name>dfs.namenode.shared.edits.dir</name>
                <value>qjournal://node2:8485;node3:8485/cluster1</value>
        </property>
        <!-- 指定journal -->
        <property>
                <name>dfs.client.failover.proxy.provider.cluster1</name>
                <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
        </property>
        <!-- 指定 cluster1 出故障时，哪个实现类负责执行故障切换 -->
        <property>
                <name>dfs.journalnode.edits.dir</name>
                <value>/home/hadoop/data/journaldata/jn</value>
        </property>
        <!-- 指定JournalNode集群在对nameNode的目录进行共享时，自己存储数据的磁盘路径 -->
        <property>
                <name>dfs.ha.fencing.methods</name>
                <value>shell(/bin/true)</value>
        </property>
        <property>
        <name>dfs.ha.fencing.ssh.private-key-files</name>
        <value>/home/hadoop/.ssh/id_rsa</value>
        </property>
        <property>
        <name>dfs.ha.fencing.ssh.connect-timeout</name>
        <value>10000</value>
        </property>
        <!-- 脑裂默认配置 -->
        <property>
                <name>dfs.namenode.handler.count</name>
                <value>100</value>
        </property>
</configuration>
